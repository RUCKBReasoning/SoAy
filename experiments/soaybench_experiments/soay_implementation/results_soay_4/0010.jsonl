{"route": "searchPerson", "result": ["Indoor Space", "Query Processing", "RFID", "Computer Science", "Indexes", "Empirical Study", "Mobile Computing", "Bluetooth", "Trajectory", "Skyline Query"], "exe_time": 13.206580638885498}
{"route": "searchPerson", "result": 478, "exe_time": 13.8840970993042}
{"route": "searchPerson", "result": "exe error", "exe_time": 12.901551246643066}
{"route": "searchPerson", "result": "Machine Learning Department, Carnegie Mellon University", "exe_time": 14.07904863357544}
{"route": "searchPerson", "result": 22375, "exe_time": 11.077345132827759}
{"route": "searchPerson", "result": 1, "exe_time": 13.599489212036133}
{"route": "searchPerson", "result": ["Ritika Pandey"], "exe_time": 9.548779010772705}
{"route": "searchPerson", "result": ["Ok-Chul Jung"], "exe_time": 10.062952280044556}
{"route": "searchPerson -> getCoauthors", "result": ["Jiawei Han", "Yu Meng", "Jiaxin Huang", "Xuan Wang", "Xiang Ren", "Yunyi Zhang", "Qi(Bran) Zhu", "Bowen Jin", "Jingbo Shang", "Qi Li (Quinn)", "Carl Yang", "Chao Zhang", "Kuansan Wang", "Junheng Hao", "Chen Liang"], "exe_time": 16.736210346221924}
{"route": "searchPerson -> getCoauthors", "result": ["Juanzi Li", "Yuxiao Dong", "Jing Zhang", "Ming Ding", "Jiezhong Qiu", "Hongxia Yang", "Xiao Liu", "Yukuo Cen", "Ying Ding", "Jimeng Sun", "Chang Zhou", "Kuansan Wang", "Hanghang Tong", "Zhengxiao Du", "Bo Chen", "Jifan Yu", "Xu Zou", "Nitesh Chawla", "Fanjin Zhang", "Zhiyuan Liu", "Michalis Vazirgiannis", "Philip S. Yu", "Zhenyu Hou", "Jingren Zhou", "Xiao Liu（Tracy Xiao Liu）"], "exe_time": 17.540302991867065}
{"route": "searchPerson -> getCoauthors", "result": ["Rongrong Ji", "Xibin Zhao", "Tat-Seng Chua", "Qi Tian", "Xuelong Li", "Wei Liu"], "exe_time": 30.622485876083374}
{"route": "searchPerson -> getCoauthors", "result": [], "exe_time": 21.53086495399475}
{"route": "searchPerson -> getPersonPubs", "result": ["Recurrent Neural Network for Text Classification with Multi-Task Learning.", "How To Fine-Tune Bert For Text Classification?", "Pre-trained Models for Natural Language Processing: A Survey", "Adversarial Multi-Task Learning For Text Classification", "Phrase dependency parsing for opinion mining", "Extractive Summarization as Text Matching", "K-Adapter - Infusing Knowledge into Pre-Trained Models with Adapters.", "FLAT: Chinese NER Using Flat-Lattice Transformer", "Convolutional Neural Tensor Network Architecture for Community-Based Question Answering.", "Long Short-Term Memory Neural Networks for Chinese Word Segmentation"], "exe_time": 22.424752235412598}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": 1248, "exe_time": 24.417526483535767}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": 2022, "exe_time": 23.50521731376648}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": ["Jessica Hwang", "Paulo Orenstein", "Karl Pfeiffer", "Judah Cohen", "Lester Mackey"], "exe_time": 23.13588786125183}
{"route": "searchPerson -> getPersonPubs", "result": ["Learning Structured Sparsity in Deep Neural Networks.", "TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning.", "Faster CNNs with Direct Sparse Convolutions and Guided Pruning", "Neural Predictor for Neural Architecture Search", "Coordinating Filters for Faster Deep Neural Networks", "Feature Space Perturbations Yield More Transferable Adversarial Examples", "Learning Intrinsic Sparse Structures within Long Short-term Memory.", "Feature Space Perturbations Yield More Transferable Adversarial Examples", "DeepHoyer: Learning Sparser Neural Network with Differentiable Scale-Invariant Sparsity Measures", "TRP: Trained Rank Pruning for Efficient Deep Neural Networks"], "exe_time": 14.400053024291992}
{"route": "searchPublication", "result": "exe error", "exe_time": 13.477229595184326}
{"route": "searchPerson -> getPersonPubs", "result": 2020, "exe_time": 22.938117265701294}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": ["Arya D. McCarthy", "Kevin P. Yancey", "Geoffrey T. LaFlair", "Jesse Egbert", "Manqian Liao", "Burr Settles"], "exe_time": 21.063626050949097}
{"route": "searchPerson -> getPersonBasicInfo", "result": "male", "exe_time": 21.73855996131897}
{"route": "searchPerson -> getPersonBasicInfo", "result": "AI Research Scientist", "exe_time": 16.84604525566101}
{"route": "searchPerson -> getPersonBasicInfo", "result": "I now work on probabilistic machine learning for automated decision-making.", "exe_time": 15.98844027519226}
{"route": "searchPerson -> getPersonBasicInfo", "result": "In July 2012, I received my bachelor degree from School of Computer Science and Technology in University of Science and Technology of China (USTC). In July 2017, I received the Ph.D. degree in the Chinese University of Hong Kong (CUHK). My thesis adviser if Prof.Jeffrey Xu Yu", "exe_time": 21.261971712112427}
{"route": "searchPerson -> getPersonBasicInfo", "result": "liyang.cs@pku.edu.cn", "exe_time": 18.19280219078064}
{"route": "searchPerson -> getPersonBasicInfo", "result": "male", "exe_time": 16.944395780563354}
{"route": "searchPerson -> getPersonBasicInfo", "result": "Senior Researcher", "exe_time": 12.737985849380493}
{"route": "searchPerson -> getPersonBasicInfo", "result": "Dr. Cha’s research is on data science and information science with an emphasis on modeling socially-relevant information propagation processes. Her work, on misinformation, poverty mapping, fraud detection, and long-tail content, has gained more than 14,000 citations and received the best paper awards at several conferences. ", "exe_time": 18.01946258544922}
{"route": "searchPerson -> getPersonBasicInfo", "result": "Virginia Tech<br>Doctor of Philosophy - PhD Computer Science<br>2018 - 2023<br><br>Harbin Institute of Technology<br>Bachelor's degree Telecommunications Engineering<br>2014 - 2018", "exe_time": 17.308745861053467}
{"route": "searchPerson -> getPersonBasicInfo", "result": "liuxt2371@gmail.com;liuxt@cse.cuhk.edu.hk", "exe_time": 17.673242568969727}
{"route": "searchPerson -> getCoauthors -> getPersonInterest", "result": [], "exe_time": 26.327393770217896}
{"route": "searchPerson -> getCoauthors -> searchPerson", "result": "Jagdish Ramakrishnan", "exe_time": 119.80913615226746}
{"route": "searchPerson -> getCoauthors -> searchPerson", "result": {"person_id": "53f4cabddabfaeea6af80f50", "name": "Linsey Pang", "relation": "coauthor"}, "exe_time": 114.38157892227173}
{"route": "searchPerson -> getCoauthors -> searchPerson", "result": [], "exe_time": 33.94069480895996}
{"route": "searchPerson -> getCoauthors -> searchPerson", "result": ["Kyle Soska", 39], "exe_time": 119.37695670127869}
{"route": "searchPerson -> getCoauthors -> searchPerson", "result": "Shengjun Huang", "exe_time": 31.07497549057007}
{"route": "searchPerson -> getCoauthors -> getCoauthors", "result": ["Jure Leskovec", "Hongyu Ren", "Xikun Zhang", "Xinyun Chen", "Denny Zhou", "Chenlin Meng", "Zijie Jay Wang", "Jason Wei", "Mo Tiwari", "Allen Nie", "Chen Henry Wu", "Aitor Lewkowycz", "Victor Zhong", "Michihiro Yasunaga", "Bailin Wang", "Alex Beutel", "Ed H. Chi", "Jilin Chen", "Cong Yu", "Denny Zhou", "Yao Qin", "Jason Wei", "Flip R. Korn", "You Wu", "Quoc Viet Le", "Yi Tay", "Ting Chen", "Dale Markowitz", "Jiawei Han", "Bill Lin", "Jingbo Shang", "Xisen Jin", "Yuning Mao", "Xiaotao Gu", "Yu Zhang", "Chi Wang", "Fei Wu", "Yizhou Sun", "Meng Jiang"], "exe_time": 27.070139169692993}
{"route": "searchPerson -> getCoauthors -> getCoauthors", "result": ["Hongyu Gong", "Yu-An Chung", "Yonghui Wu", "Zhifeng Chen", "Awni Hannun", "Yuan Cao", "Yu-An Chung", "Li-wei H. Lehman", "Tim Kraska", "Zhifeng Chen", "Yuan Cao", "Quoc Viet Le", "Mia Chen", "Wei-Ning Hsu", "Xuan-Phi Nguyen"], "exe_time": 23.728433847427368}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": "We propose a distance supervised relation extraction approach for long-tailed, imbalanced data which is prevalent in real-world settings. Here, the challenge is to learn accurate few-shot models for classes existing at the tail of the class distribution, for which little data is available. Inspired by the rich semantic correlations between classes at the long tail and those at the head, we take advantage of the knowledge from data-rich classes at the head of the distribution to boost the performance of the data-poor classes at the tail. First, we propose to leverage implicit relational knowledge among class labels from knowledge graph embeddings and learn explicit relational knowledge using graph convolution networks. Second, we integrate that relational knowledge into relation extraction model by coarse-to-fine knowledge-aware attention mechanism. We demonstrate our results for a large-scale benchmark dataset which show that our approach significantly outperforms other baselines, especially for long-tail relations.", "exe_time": 22.3254554271698}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": "https://static.aminer.cn/upload/pdf/program/59a02e43b161e8ad1a7b6dd0_0.pdf", "exe_time": 24.429698944091797}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": {"info": {"name": "ICML"}, "volume": "abs/2005.06392"}, "exe_time": 28.686934232711792}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": "ABSTRACTSpike train classification is an important problem in many areas such as healthcare and mobile sensing, where each spike train is a high-dimensional time series of binary values. Conventional research on spike train classification mainly focus on developing Spiking Neural Networks (SNNs) under resource-sufficient settings (e.g., on GPU servers). The neurons of the SNNs are usually densely connected in each layer. However, in many real-world applications, we often need to deploy the SNN models on resource-constrained platforms (e.g., mobile devices) to analyze high-dimensional spike train data. The high resource requirement of the densely-connected SNNs can make them hard to deploy on mobile devices. In this paper, we study the problem of energy-efficient SNNs with sparsely-connected neurons. We propose an SNN model with sparse spatio-temporal coding. Our solution is based on the re-parameterization of weights in an SNN and the application of sparsity regularization during optimization. We compare our work with the state-of-the-art SNNs and demonstrate that our sparse SNNs achieve significantly better computational efficiency on both neuromorphic and standard datasets with comparable classification accuracy. Furthermore, compared with densely-connected SNNs, we show that our method has a better capability of generalization on small-size datasets through extensive experiments.", "exe_time": 23.503880500793457}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": "https://cz5waila03cyo0tux1owpyofgoryroob.oss-cn-beijing.aliyuncs.com/2C/5C/AE/2C5CAEDFEDEE9E274C963DEBB2B4E390.pdf", "exe_time": 56.600340604782104}
{"route": "searchPerson -> getPersonPubs -> getPublication", "result": {"info": {"name": "Proceedings of the 28th ACM International Conference on Information and Knowledge Management"}, "issue": "", "type": 11, "volume": "abs/1810.11921"}, "exe_time": 21.93971824645996}